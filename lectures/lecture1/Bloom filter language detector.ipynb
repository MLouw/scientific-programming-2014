{
 "metadata": {
  "name": "",
  "signature": "sha256:b86e6d03d917e1c8ea30cb1a12b61a3aa0ae6b31f9ca4e6543a9b3d7ee474ee5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Detecting the language of a sentence using a Bloom filter"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise you will be implementing a simple language detector, which uses a Bloom filter as its main data structure. For training and testing the code, we use sentences from company reviews, originally posted on [Trustpilot](trustpilot.com).\n",
      "\n",
      "We begin by defining additional hash functions. \n",
      "\n",
      "In the cell below, `random_integers` is initialized with large non-negative integers. Each of the functions combine a different random number with the output of the Python `hash` function using a binary *XOR* operation. \n",
      "\n",
      "(If you haven't heard about *XOR* before, don't worry: it's not essential. Suffice to say that `hash1`, `hash2`, and `hash3` are three different hash functions.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "import sys\n",
      "import codecs\n",
      "\n",
      "random_integers = [random.randrange(0, sys.maxint) for i in range(10)]\n",
      "def hash1(obj): \n",
      "    return hash(obj) ^ random_integers[0] # ^ is XOR\n",
      "\n",
      "def hash2(obj):\n",
      "    return hash(obj) ^ random_integers[1]\n",
      "\n",
      "def hash3(obj):\n",
      "    return hash(obj) ^ random_integers[2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Verify that the hash functions defined above are indeed different. Test it by hand with a couple of strings of your choice."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_bloom_filter(filter_size):\n",
      "    return [0 for i in range(filter_size)]\n",
      "\n",
      "def add_to_filter(obj, bloom_filter):\n",
      "    bloom_filter[hash1(obj) % len(bloom_filter)] = 1\n",
      "    bloom_filter[hash2(obj) % len(bloom_filter)] = 1\n",
      "    bloom_filter[hash3(obj) % len(bloom_filter)] = 1\n",
      "\n",
      "def is_in_filter(obj, bloom_filter):\n",
      "    return bloom_filter[hash1(obj) % len(bloom_filter)] \\\n",
      "        and bloom_filter[hash2(obj) % len(bloom_filter)] \\\n",
      "        and bloom_filter[hash3(obj) % len(bloom_filter)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Read in a sample of ten thousand sentences of French and English, taken from the trustpilot.com site."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_review_sentences(filename):\n",
      "    sentences = []\n",
      "    for line in codecs.open(filename, encoding='utf-8'):\n",
      "        tokens = line.strip().split(\" \")\n",
      "        tokens = [token for token in tokens]\n",
      "        sentences.append(tokens)\n",
      "    return sentences\n",
      "        \n",
      "en_sentences = read_review_sentences(\"trust_pilot.10k.english\")\n",
      "fr_sentences = read_review_sentences(\"trust_pilot.10k.french\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Modify the `read_review_sentences` so it only returns tokens where all characters are alphabetic. This skips URLs, numbers, punctuation, etc. Check that your code works as expected."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We divide the sentences up into a *training* and a *testing* section."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "en_sentences_train = en_sentences[:8000]\n",
      "en_sentences_test = en_sentences[8000:]\n",
      "\n",
      "fr_sentences_train = fr_sentences[:8000]\n",
      "fr_sentences_test = fr_sentences[8000:]                      "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we train a bloom filter on each of the languages."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "BLOOM_FILTER_SIZE = 100000\n",
      "\n",
      "fr_bloom = make_bloom_filter(BLOOM_FILTER_SIZE)\n",
      "for sent in fr_sentences_train:\n",
      "    for token in sent:\n",
      "        add_to_filter(token, fr_bloom)\n",
      "\n",
      "en_bloom = make_bloom_filter(BLOOM_FILTER_SIZE)\n",
      "for sent in en_sentences_train:\n",
      "    for token in sent:\n",
      "        add_to_filter(token, en_bloom)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below we evaluate how accurate our language detector is."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_french(sent):\n",
      "    return True\n",
      "\n",
      "french_scores = [is_french(sent) for sent in fr_sentences_test] \n",
      "english_scores = [not is_french(sent) for sent in en_sentences_test]\n",
      "\n",
      "print \"French accuracy\", sum(french_scores) / float(len(french_scores))\n",
      "print \"English accuracy\", sum(english_scores) / float(len(english_scores))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Provide the implementation of the `is_french` function. It should return `True` whenever the number of French words in a sentence exceeds the number of English words."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise** Modify the `BLOOM_FILTER_SIZE`, adjusting it up and down. Try different values and observe the influence on the language detection accuracies. Does filter size affect both languages equally?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}